{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b929507-26ec-4af0-ab2f-799985244821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../demo_setup/00.Initial_library_install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503f8b89-773c-497e-9a91-cf2464034f9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Model Training and Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "97ad0e76-d451-4bb2-a78c-62352c3ff88b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow.lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from bayes_opt import BayesianOptimization\n",
    "from mlflow.models import infer_signature\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from databricks.feature_engineering.entities.feature_lookup import FeatureLookup\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "fe = FeatureEngineeringClient()\n",
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d04200-ee42-4f89-b6df-5ded6642310a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We use `mlflow.create_experiment()` to explicitly define and organize our ML experiment, ensuring that all runs related to this use case (e.g., iron ore processing predictions) are logged under a dedicated experiment in MLflow.\n",
    "\n",
    "This allows us to:\n",
    "- üóÇÔ∏è Group related runs together for easier comparison and tracking\n",
    "- üìä Log and visualize key metrics, parameters, models, and artifacts in a central place\n",
    "- üîÅ Revisit and reproduce results consistently over time\n",
    "- üìé Maintain a clear audit trail of the model development process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f3180d70-67ef-4213-9d1d-12c479a15c9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_name = dbutils.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "#create an experiment in the users folder on this workspace\n",
    "EXP_NAME = f\"/Users/{user_name}/process_control_demo_experiments\"\n",
    "\n",
    "if mlflow.get_experiment_by_name(EXP_NAME) is None:\n",
    "    print(f\"creating experiment {EXP_NAME}\")\n",
    "    mlflow.create_experiment(name=EXP_NAME)\n",
    "experiment = mlflow.set_experiment(EXP_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df07b25-7e8d-4c59-acde-6b78aa95fa73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.1 üìÇ Load Dataset & Split into Train, Test, and Out-of-Time Sets\n",
    "\n",
    "In this step, we load the prepared dataset and split it into training, testing, and out-of-time (OOT) sets. This allows us to train the model, evaluate its performance, and validate generalisation on unseen data that simulates future conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0ec4b112-dda1-47a8-a21f-d70136c95daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_feature_table(table_name, data):\n",
    "    # Drop the fs table if it was already existing to cleanup the demo state\n",
    "    drop_fs_table(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name}\")\n",
    "\n",
    "    df = spark.createDataFrame(data)\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "        ALTER TABLE {DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name} ALTER COLUMN date SET NOT NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        spark.sql(f\"\"\"\n",
    "            ALTER TABLE {DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name}\n",
    "            ADD CONSTRAINT pk PRIMARY KEY(date)\n",
    "        \"\"\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Create feature table using the feature store client\n",
    "    fs.create_table(\n",
    "        name=f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name}\",\n",
    "        primary_keys=[\"date\"],\n",
    "        df=df,\n",
    "        description=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492a8de1-76bd-4f2b-be78-b89576a246fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df_master = fs.read_table(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.fs_gold_iop_features\")\n",
    "\n",
    "# Convert data into pandas dataframe\n",
    "pandas_df = df_master.toPandas()\n",
    "\n",
    "# Split dataset into train, test and out-of-time validation sets for counterfatual evaluation\n",
    "train_and_test_ds = df_master[df_master.date < '2017-08-25'].toPandas()\n",
    "oot_ds = df_master[df_master.date >= '2017-08-25']\n",
    "oot_ds = oot_ds.orderBy(oot_ds.date.asc())\n",
    "print((train_and_test_ds.count(), len(train_and_test_ds.columns)), (oot_ds.count(), len(oot_ds.columns)))\n",
    "\n",
    "save_feature_table('ml_train_test_data', train_and_test_ds)\n",
    "save_feature_table('ml_oot_data', oot_ds.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2243b2-1fa8-4f8c-aaa2-09e6e02af746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# list of features to train model\n",
    "model_features = [\n",
    "  'Percent_Iron_Feed',\n",
    "  'Percent_Silica_Feed',\n",
    "  'Starch_Flow',\n",
    "  'Amina_Flow', \n",
    "  'Ore_Pulp_Flow', \n",
    "  'Ore_Pulp_pH', \n",
    "  'Ore_Pulp_Density',\n",
    "  'Flotation_Column_01_Air_Flow',\n",
    "  'Flotation_Column_02_Air_Flow',\n",
    "  'Flotation_Column_03_Air_Flow',\n",
    "  'Flotation_Column_04_Air_Flow',\n",
    "  'Flotation_Column_05_Air_Flow',\n",
    "  'Flotation_Column_06_Air_Flow',\n",
    "  'Flotation_Column_07_Air_Flow',\n",
    "  'Flotation_Column_01_Level',\n",
    "  'Flotation_Column_02_Level',\n",
    "  'Flotation_Column_03_Level',\n",
    "  'Flotation_Column_04_Level',\n",
    "  'Flotation_Column_05_Level',\n",
    "  'Flotation_Column_06_Level',\n",
    "  'Flotation_Column_07_Level',\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06f31e5-7680-4ba1-a614-bfbb7b01f929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.2 Model Hyperparameter Tuning \n",
    "\n",
    "In this section, we demonstrate how to use Hyperopt for automated hyperparameter tuning and how to leverage **MLflow** to track experiments, log performance metrics, and capture model explainability outputs.\n",
    "\n",
    "This example:\n",
    "- Splits the dataset into training and testing sets\n",
    "- Defines a hyperparameter search space for a LightGBM model\n",
    "- Uses Hyperopt to find the best combination of parameters that minimises Mean Absolute Percentage Error (MAPE)\n",
    "- Logs all relevant information to MLflow, including:\n",
    "  - Input hyperparameters\n",
    "  - Train/test metrics for each run \n",
    "  - The final trained model (versioned in MLflow)\n",
    "  - SHAP-based feature importance plots and summary visualisations for explainability\n",
    "\n",
    "This workflow not only shows how to automate model selection, but also how to capture rich experiment metadata to support reproducibility, comparison, and collaboration across the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bb5dd1-9d70-496e-9e29-6c8477a616db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run Hyperopt tuning\n",
    "def run_tuning(target, run_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "      train_and_test_ds[model_features], train_and_test_ds[target], test_size=0.2, random_state=42)\n",
    "    \n",
    "    space = {\n",
    "      \"run_name\": run_name,\n",
    "      \"n_estimators\": hp.choice('n_estimators', [100, 150, 200, 500]),\n",
    "      \"learning_rate\": hp.choice('learning_rate', [0.1, 0.25, 0.5]),\n",
    "      \"num_leaves\": hp.choice('num_leaves', [5, 10, 50, 100]),\n",
    "      \"max_depth\": hp.choice('max_depth', [5, 10, 15, 30]),\n",
    "      \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    # Objective function for Hyperopt\n",
    "    def objective(params):\n",
    "        with mlflow.start_run(run_name=params[\"run_name\"], nested=True):\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            train_preds = model.predict(X_train)\n",
    "            test_preds = model.predict(X_test)\n",
    "\n",
    "            train_mape = mean_absolute_percentage_error(y_train, train_preds)\n",
    "            test_mape = mean_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "            # Log metrics and parameters\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metric(\"train_mape\", train_mape)\n",
    "            mlflow.log_metric(\"test_mape\", test_mape)\n",
    "\n",
    "            return {'loss': test_mape, 'status': STATUS_OK}\n",
    "\n",
    "    with mlflow.start_run(run_name=space[\"run_name\"], experiment_id=experiment.experiment_id):\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials\n",
    "        )\n",
    "\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "\n",
    "        # Map index-based params back to actual values\n",
    "        best_params[\"num_leaves\"] = int([5, 10, 50, 100][best_params[\"num_leaves\"]])\n",
    "        best_params[\"max_depth\"] = int([5, 10, 15, 30][best_params[\"max_depth\"]])\n",
    "        best_params[\"n_estimators\"] = int(\n",
    "            [100, 150, 200, 500][best_params[\"n_estimators\"]]\n",
    "        )\n",
    "        best_params[\"learning_rate\"] = [0.1, 0.25, 0.5][best_params[\"learning_rate\"]]\n",
    "\n",
    "        # Train final model\n",
    "        final_model = lgb.LGBMRegressor(**best_params)\n",
    "        final_model.fit(X_train, y_train)\n",
    "\n",
    "        train_preds = final_model.predict(X_train)\n",
    "        test_preds = final_model.predict(X_test)\n",
    "\n",
    "        train_mape = mean_absolute_percentage_error(y_train, train_preds)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "        # Log final model and performance\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"final_train_mape\", train_mape)\n",
    "        mlflow.log_metric(\"final_test_mape\", test_mape)\n",
    "        mlflow.lightgbm.log_model(\n",
    "            final_model, f\"lightgbm_{run_name}_model\", signature=signature\n",
    "        )\n",
    "\n",
    "        # Model explainability with SHAP\n",
    "        explainer = shap.Explainer(final_model, X_train)\n",
    "        shap_values = explainer(X_test, check_additivity=False)\n",
    "\n",
    "        # Plot summary of SHAP values\n",
    "        shap.summary_plot(shap_values, X_test, show=False)\n",
    "        plot_path = f\"../outputs/shap_summary_plot_{run_name}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(plot_path, artifact_path=\"shap_explainability\")\n",
    "\n",
    "        # Feature importance bar plot\n",
    "        plt.figure()\n",
    "        shap.plots.bar(shap_values, show=False)\n",
    "        bar_path = f\"../outputs/shap_bar_{run_name}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(bar_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(bar_path, artifact_path=\"shap_explainability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86607a97-ac54-4318-99f6-22ff041bace2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2.1 Fe Concentrate Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b950dd4e-1b52-42bf-8a6b-1d9080a52af8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target = 'Percent_Iron_Concentrate'\n",
    "run_name = 'iron_ore_quality_fe_concentrate'\n",
    "run_tuning(target, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e8d458-b6d3-4e54-a837-1ab63946c623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2.2 Si Concentrate Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c00be53-bea6-452f-9730-f88963c422e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target = 'Percent_Silica_Concentrate'\n",
    "run_name = 'iron_ore_quality_si_concentrate'\n",
    "\n",
    "run_tuning(target, run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6afaaa25-2d38-4cbb-8719-58e9c1b99cb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.3 Identify Best Model and Register to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "375c139f-6d0f-4b32-976e-5a250af6f331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model_si = mlflow.search_runs(\n",
    "  experiment_ids=experiment.experiment_id,\n",
    "  order_by=[\"metrics.final_test_mape\"],\n",
    "  max_results=1,\n",
    "  filter_string=\"status = 'FINISHED' and run_name='iron_ore_quality_si_concentrate'\"\n",
    ")\n",
    "\n",
    "best_model_fe = mlflow.search_runs(\n",
    "  experiment_ids=experiment.experiment_id,\n",
    "  order_by=[\"metrics.final_test_mape\"],\n",
    "  max_results=1,\n",
    "  filter_string=\"status = 'FINISHED' and run_name='iron_ore_quality_fe_concentrate'\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2fac7cf-2efe-4ba0-9466-7fe623ddf9a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SI\n",
    "mv = mlflow.register_model(\n",
    "    f\"runs:/{best_model_si.iloc[0]['run_id']}/lightgbm_iron_ore_quality_si_concentrate_model\", f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.si_model\"\n",
    ")\n",
    "\n",
    "alias = \"Champion\" if mv.version == '1' else \"Challenger\"\n",
    "client.set_registered_model_alias(\n",
    "  f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.si_model\", alias, mv.version\n",
    ")\n",
    "\n",
    "# FE\n",
    "mv = mlflow.register_model(\n",
    "  f\"runs:/{best_model_fe.iloc[0]['run_id']}/lightgbm_iron_ore_quality_fe_concentrate_model\", \n",
    "  f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.fe_model\"\n",
    ")\n",
    "alias = \"Champion\" if mv.version == '1' else \"Challenger\"\n",
    "client.set_registered_model_alias(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.fe_model\", alias, mv.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d59df2f-81de-406d-ad61-b887d1a8eed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.4 Model Inference\n",
    "\n",
    "In this section, we showcase how champion models are seamlessly loaded from Unity Catalog for model inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bfbc670-6839-4e3c-bdf4-6d182d110429",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.4.1 Load Champion Models & Model Features from UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d80b985c-40d8-4cb4-9bd7-6823a420e5d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Si Concentrate Model:\n",
    "si_model = mlflow.pyfunc.load_model(f'models:/{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.si_model@Champion')\n",
    "si_input_schema = si_model.metadata.get_input_schema()\n",
    "si_input_columns = [col.name for col in si_input_schema]\n",
    "si_label = [t.name for t in si_model.metadata.get_output_schema()][0]\n",
    "\n",
    "# Fe Concentrate Model:\n",
    "fe_model = mlflow.pyfunc.load_model(f'models:/{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.fe_model@Champion')\n",
    "fe_input_schema = fe_model.metadata.get_input_schema()\n",
    "fe_input_columns = [col.name for col in fe_input_schema]\n",
    "fe_label = [t.name for t in fe_model.metadata.get_output_schema()][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb951d67-6c24-4b0a-befd-8da9c6bfd891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 3.4.2 Predict Si and Fe and Save Results to a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca1ded24-1d09-4794-ba39-054ad87c44d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "oot_ds = oot_ds.toPandas()\n",
    "si_predictions = si_model.predict(oot_ds[si_input_columns])\n",
    "fe_predictions = fe_model.predict(oot_ds[fe_input_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc0e8301-eb5b-42ec-9501-dc276acf8837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Calculate MAPE for Si predictions\n",
    "si_mape = mean_absolute_percentage_error(oot_ds[si_label], si_predictions)\n",
    "\n",
    "# Calculate MAPE for Fe predictions\n",
    "fe_mape = mean_absolute_percentage_error(oot_ds[fe_label], fe_predictions)\n",
    "\n",
    "si_mape, fe_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae6c9b2-d8cc-437d-8789-6ef8c9bb4099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"b290X2RzWyJzaV9wcmVkaWN0aW9uIl0gPSBzaV9wcmVkaWN0aW9ucwpvb3RfZHNbImZlX3ByZWRpY3Rpb24iXSA9IGZlX3ByZWRpY3Rpb25zCgpkaXNwbGF5KG9vdF9kcykKCnRhYmxlX25hbWUgPSAiZ29sZF9pcm9uX29yZV9wcmVkaWN0aW9ucyIKc3BhcmtfZGYgPSBzcGFyay5jcmVhdGVEYXRhRnJhbWUob290X2RzKQpzcGFya19kZi53cml0ZS5mb3JtYXQoImRlbHRhIikubW9kZSgib3ZlcndyaXRlIikuc2F2ZUFzVGFibGUoZiJ7REVGQVVMVF9DQVRBTE9HfS57REVGQVVMVF9TQ0hFTUF9Lnt0YWJsZV9uYW1lfSIp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewb78e45b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewb78e45b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewb78e45b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewb78e45b) SELECT `date`,SUM(`si_prediction`) `column_b406af35757`,SUM(`Percent_Silica_Concentrate`) `column_b406af35760` FROM q GROUP BY `date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewb78e45b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Si Concentrate",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "date",
             "id": "column_b406af35754"
            },
            "y": [
             {
              "column": "si_prediction",
              "id": "column_b406af35757",
              "transform": "SUM"
             },
             {
              "column": "Percent_Silica_Concentrate",
              "id": "column_b406af35760",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_b406af35757": {
             "name": "Si % Concentrate - Prediction",
             "type": "line",
             "yAxis": 0
            },
            "column_b406af35760": {
             "name": "Si % Concentrate - Actuals",
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Timestamp"
            },
            "type": "-"
           },
           "yAxis": [
            {
             "title": {
              "text": "Si % Concentrate"
             },
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "254d872f-5c95-431f-8141-8864838d0090",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 17.25,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "date",
           "type": "column"
          },
          {
           "alias": "column_b406af35757",
           "args": [
            {
             "column": "si_prediction",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_b406af35760",
           "args": [
            {
             "column": "Percent_Silica_Concentrate",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"b290X2RzWyJzaV9wcmVkaWN0aW9uIl0gPSBzaV9wcmVkaWN0aW9ucwpvb3RfZHNbImZlX3ByZWRpY3Rpb24iXSA9IGZlX3ByZWRpY3Rpb25zCgpkaXNwbGF5KG9vdF9kcykKCnRhYmxlX25hbWUgPSAiZ29sZF9pcm9uX29yZV9wcmVkaWN0aW9ucyIKc3BhcmtfZGYgPSBzcGFyay5jcmVhdGVEYXRhRnJhbWUob290X2RzKQpzcGFya19kZi53cml0ZS5mb3JtYXQoImRlbHRhIikubW9kZSgib3ZlcndyaXRlIikuc2F2ZUFzVGFibGUoZiJ7REVGQVVMVF9DQVRBTE9HfS57REVGQVVMVF9TQ0hFTUF9Lnt0YWJsZV9uYW1lfSIp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView2c6a13b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView2c6a13b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView2c6a13b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView2c6a13b) SELECT `date`,SUM(`fe_prediction`) `column_b406af35768`,SUM(`Percent_Iron_Concentrate`) `column_b406af35771` FROM q GROUP BY `date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView2c6a13b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Fe Concentrate",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "date",
             "id": "column_b406af35765"
            },
            "y": [
             {
              "column": "fe_prediction",
              "id": "column_b406af35768",
              "transform": "SUM"
             },
             {
              "column": "Percent_Iron_Concentrate",
              "id": "column_b406af35771",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_b406af35768": {
             "name": "Fe % Concentrate - Prediction",
             "type": "line",
             "yAxis": 0
            },
            "column_b406af35771": {
             "name": "Fe % Concentrate -  Actual",
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Timestamp"
            },
            "type": "-"
           },
           "yAxis": [
            {
             "title": {
              "text": "Fe % Concentrate"
             },
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "bacd1746-599c-4245-8920-ac94cd4046ff",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 18.25,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "date",
           "type": "column"
          },
          {
           "alias": "column_b406af35768",
           "args": [
            {
             "column": "fe_prediction",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_b406af35771",
           "args": [
            {
             "column": "Percent_Iron_Concentrate",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oot_ds[\"si_prediction\"] = si_predictions\n",
    "oot_ds[\"fe_prediction\"] = fe_predictions\n",
    "\n",
    "display(oot_ds)\n",
    "\n",
    "table_name = \"gold_iron_ore_predictions\"\n",
    "spark_df = spark.createDataFrame(oot_ds)\n",
    "spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3129e8e7-9026-494b-a986-6b95f5e2e2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.5 Evaluate Model Performance with MLFLow Evaluate\n",
    "\n",
    "MLFLow has inbuilt evaluation capabilties that allows you to generate a comprehensive evaluation against a given dataset, for a suite of metrics. This triggers a MLFLow evaluation that captures the evaluation and all of the assiociated artifacts. The evaluation can be accessed to compare across models or to use the results in downstream processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0cf218d-4071-463d-8c82-3449bd9c05b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "EXP_NAME = f\"/Users/{user_name}/process_control_demo_experiments_eval\"\n",
    "\n",
    "if mlflow.get_experiment_by_name(EXP_NAME) is None:\n",
    "    print(f\"creating experiment {EXP_NAME}\")\n",
    "    mlflow.create_experiment(name=EXP_NAME)\n",
    "experiment = mlflow.set_experiment(EXP_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=\"iron_ore_quality_eval\", experiment_id=experiment.experiment_id):\n",
    "    si_eval = mlflow.models.evaluate(\n",
    "        model=si_model,\n",
    "        data=oot_ds,\n",
    "        targets=\"Percent_Silica_Concentrate\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=[\"default\"],\n",
    "    )\n",
    "\n",
    "    fe_eval = mlflow.models.evaluate(\n",
    "        model=fe_model,\n",
    "        data=oot_ds,\n",
    "        targets=\"Percent_Iron_Concentrate\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=[\"default\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a24442-af94-48a8-941a-d50fcb71cf73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"All Metrics:\")\n",
    "for metric_name, value in fe_eval.metrics.items():\n",
    "    print(f\"  {metric_name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa957c59-26e8-4d6f-b3a5-9fbda97631f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.6 AutoML\n",
    "\n",
    "**Databricks AutoML** simplifies the model development process by automatically running a series of experiments to identify the best-performing model for your dataset. You can easily select the training data, specify which features to include or exclude, and configure key model parameters ‚Äî all while Databricks handles model selection, tuning, and tracking behind the scenes.\n",
    "\n",
    "### üß† Steps to Run AutoML in Databricks\n",
    "\n",
    "- Launch AutoML\n",
    "  - From the Databricks workspace UI, go to the \"Machine Learning\" section.\n",
    "  - Click \"Create AutoML experiment\".\n",
    "- Configure the experiment\n",
    "  - Select the task type: Classification, Regression, or Forecasting.\n",
    "  - Choose your training dataset and target column.\n",
    "  - Optionally configure:\n",
    "    - Columns to include/exclude\n",
    "    - Primary metric (e.g., accuracy, MAPE, AUC)\n",
    "    - Runtime limit and experiment name\n",
    "- Run the AutoML experiment\n",
    "  - Databricks AutoML will:\n",
    "    - Profile your dataset\n",
    "    - Automatically preprocess data (e.g., encoding, imputation)\n",
    "    - Train and evaluate multiple models using different algorithms and hyperparameters\n",
    "    - Track results in MLflow and log the full pipeline in a generated notebook\n",
    "- Review the results\n",
    "  - Explore the leaderboard of model runs, ranked by your selected metric\n",
    "  - Open the generated notebook to inspect preprocessing, model training code, and evaluation\n",
    "  - Review feature importance and other insights\n",
    "- Register or deploy the best model\n",
    "  - Register the top-performing model in the MLflow Model Registry\n",
    "  - Optionally deploy the model for batch or real-time inference\n",
    "\n",
    "![](/Workspace/Shared/iron_ore_precessing_demo/demo_setup/images/automl-data-selection.png)\n",
    "![](/Workspace/Shared/iron_ore_precessing_demo/demo_setup/images/automl-setup.png)\n",
    "\n",
    "Once the training is complete, you can see the resulting runs, as well as the notebook that was used to generate the best model.\n",
    "\n",
    "![](/Workspace/Shared/iron_ore_precessing_demo/demo_setup/images/automl-complete.png)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03. Model Training and Experimentation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
