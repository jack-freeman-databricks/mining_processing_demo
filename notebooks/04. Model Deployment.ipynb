{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14c73194-c121-4dac-b52d-6e209cba8043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00.set_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb949b49-8a48-424e-8ecf-951394ec907e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4. ðŸš€ Model Serving\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../demo_setup/images/model_serving.png\" width=\"1200px\"/> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6821df4-5909-4154-ae5f-21f992cdf742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Simplified deployment for all AI models and agents\n",
    "\n",
    "Deploy any model type, from pretrained open source models to custom models built on your own data â€” on both CPUs and GPUs. Automated container build and infrastructure management reduce maintenance costs and speed up deployment so you can focus on building your AI agent systems and delivering value faster for your business\n",
    "\n",
    "#### Unified management for all models\n",
    "\n",
    "Manage all models, including custom ML models like PyFunc, scikit-learn and LangChain, foundation models (FMs) on Databricks like Llama 3, MPT and BGE, and foundation models hosted elsewhere like ChatGPT, Claude 3, Cohere and Stable Diffusion. Model Serving makes all models accessible in a unified user interface and API, including models hosted by Databricks, or from another model provider on Azure or AWS.\n",
    "\n",
    "\n",
    "#### Governance built-in\n",
    "\n",
    "Integrate with Mosaic AI Gateway to meet stringent security and advanced governance requirements. You can enforce proper permissions, monitor model quality, set rate limits, and track lineage across all models whether they are hosted by Databricks or on any other model provider.\n",
    "\n",
    "![](https://www.databricks.com/sites/default/files/2023-09/simplified-deployment.png?v=1696033263)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f545a3b-4bda-4c30-9a9d-ed4fb2bddb3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4.1 ðŸš€ CICD with Deployment Jobs\n",
    "\n",
    "A key final step in the end-to-end machine learning lifecycle is to deploy our model as a REST API endpoint using **Databricks Model Serving.**\n",
    "\n",
    "To accomplish this we will leverage best practice with **CICD** (continuous integration, continuous deployment) to automatically deploy our model once a new version is registered into unity catalog. We accomplish this via **Deployment Jobs.**\n",
    "\n",
    "![](../demo_setup/images/simple-deployment-job.png)\n",
    "\n",
    "Our Deployment job has the below steps:\n",
    "- Approve model deployment\n",
    "- Deploy new version of the model as a REST endpoint\n",
    "\n",
    "This process is fully automated, all it requires is someone to approve the deployment after the job detects a new model version has been registered.\n",
    "\n",
    "![](../demo_setup/images/deployment_approval.png)\n",
    "\n",
    "See documentation here: [Deployment Jobs](https://docs.databricks.com/aws/en/mlflow/deployment-job)\n",
    "\n",
    "To view our deployment job we can follow this link:\n",
    "[Deployment Job for Si Model](https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/mining_iron_ore_processing_demo_catalog/iop_schema/si_model?o=1444828305810485)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b43872-dff3-431e-9c52-c03f5785f3e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 4.2 ðŸš€ (Optional) Manually Serving the Model as a Real-Time Endpoint\n",
    "\n",
    "This code demonstrates how to deploy a trained ML model as a real-time REST API endpoint using **Databricks Model Serving** â€” often we would leverage automation to deploy model serving endpoints, however sometimes we may want to serve a model outside of a **CICD** workflow.\n",
    "\n",
    "Here's what the code does:\n",
    "- Inputs: It takes a model name and version (typically registered in the MLflow Model Registry).\n",
    "- Constructs a fully qualified model name (catalog.database.model_name) for serving.\n",
    "- Creates or updates a serving endpoint using the WorkspaceClient from the Databricks SDK.\n",
    "- Defines the endpoint configuration:\n",
    "  - Uses ServedEntityInput to specify the model version, workload size, and whether to enable scale-to-zero (cost-efficient).\n",
    "  - Enables auto-capture of inference inputs and outputs into a Delta table for auditing, monitoring, or retraining (via AutoCaptureConfigInput).\n",
    "  - If the endpoint already exists and force_update=True, it updates the configuration to serve the new model version.\n",
    "\n",
    "ðŸ’¡ This allows teams to rapidly deploy production-grade ML models with built-in observability and governance â€” without needing to manage infrastructure manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de569f6c-e216-422f-8c32-df60920486e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from mlflow.tracking import MlflowClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import ServedEntityInput, EndpointCoreConfigInput, AutoCaptureConfigInput\n",
    "\n",
    "def serve_model(model_name, model_version):\n",
    "    model_FQDN = f\"{catalog_name}.{schema_name}.{model_name}\"\n",
    "    serving_endpoint_name = f\"process_demo_{model_name}\"\n",
    "    w = WorkspaceClient()\n",
    "    endpoint_config = EndpointCoreConfigInput(\n",
    "        name=serving_endpoint_name,\n",
    "        served_entities=[\n",
    "            ServedEntityInput(\n",
    "                entity_name=model_FQDN,\n",
    "                entity_version=model_version,\n",
    "                scale_to_zero_enabled=True,\n",
    "                workload_size=\"Small\"\n",
    "            )\n",
    "        ],\n",
    "        auto_capture_config = AutoCaptureConfigInput(catalog_name=catalog_name, schema_name=schema_name, enabled=True, table_name_prefix=f\"{model_name}_payload_inference_table\" )\n",
    "    )\n",
    "\n",
    "    force_update = True #Set this to True to release a newer version (the demo won't update the endpoint to a newer model version by default)\n",
    "    existing_endpoint = next((e for e in w.serving_endpoints.list() if e.name == serving_endpoint_name), None)\n",
    "    if existing_endpoint == None:\n",
    "        print(f\"Creating the endpoint {serving_endpoint_name}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "        w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config)\n",
    "    else:\n",
    "        print(f\"endpoint {serving_endpoint_name} already exist...\")\n",
    "        if force_update:\n",
    "            w.serving_endpoints.update_config_and_wait(served_entities=endpoint_config.served_entities, name=serving_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f392125-1781-4acc-a409-d2e9ef245079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "fe_model_version_uri = f\"{catalog_name}.{schema_name}.fe_model\"\n",
    "si_model_version_uri = f\"{catalog_name}.{schema_name}.si_model\"\n",
    "\n",
    "# Load the model from Unity Catalog via the alias \"Champion\"\n",
    "fe_model_details = client.get_model_version_by_alias(fe_model_version_uri, \"Champion\")\n",
    "fe_model_version = fe_model_details.version\n",
    "\n",
    "# Load the model from Unity Catalog via the alias \"Champion\"\n",
    "si_model_details = client.get_model_version_by_alias(si_model_version_uri, \"Champion\")\n",
    "si_model_version = si_model_details.version\n",
    "\n",
    "# Serve the models\n",
    "serve_model(\"fe_model\", fe_model_version)\n",
    "serve_model(\"si_model\", si_model_version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04. Model Deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
