{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c389bb-80f9-467a-875a-32efa50b8e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 5. Optimisation\n",
    "\n",
    " We'll walk through an optimisation use case focused on maximizing iron ore concentrate yield, while maintaining stable levels of silicon (Si) concentrate. This demonstrates how predictive models can be integrated into operational workflows to drive smarter, constraint-aware decisions in mineral processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0d8ab19a-299e-4f0d-9271-789073bf0d2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../demo_setup/00.Initial_library_install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3518451a-478a-4c77-a433-9a81231d603c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from databricks.feature_engineering.entities.feature_lookup import FeatureLookup\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "fe = FeatureEngineeringClient()\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "train_and_test_ds = fs.read_table(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.ml_train_test_data\").toPandas()\n",
    "oot_ds = fs.read_table(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.ml_oot_data\")\n",
    "oot_ds = oot_ds.toPandas()\n",
    "\n",
    "# Si Concentrate Model:\n",
    "si_model = mlflow.pyfunc.load_model(f'models:/{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.si_model@Champion')\n",
    "si_input_schema = si_model.metadata.get_input_schema()\n",
    "si_input_columns = [col.name for col in si_input_schema]\n",
    "si_label = [t.name for t in si_model.metadata.get_output_schema()][0]\n",
    "\n",
    "# Fe Concentrate Model:\n",
    "fe_model = mlflow.pyfunc.load_model(F'models:/{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.fe_model@Champion')\n",
    "fe_input_schema = fe_model.metadata.get_input_schema()\n",
    "fe_input_columns = [col.name for col in fe_input_schema]\n",
    "fe_label = [t.name for t in fe_model.metadata.get_output_schema()][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd7f0dd-1619-44ed-8ea1-40faa90a7013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5.1 Set Optimisation Parameters and Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "804ab392-7fd9-4f1d-8f91-f2fab1b24f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define bounds for the 3 features (customize as needed)\n",
    "pbounds = {\n",
    "    'Starch_Flow': (train_and_test_ds['Starch_Flow'].min(), train_and_test_ds['Starch_Flow'].max()),\n",
    "    'Amina_Flow': (train_and_test_ds['Amina_Flow'].min(), train_and_test_ds['Amina_Flow'].max()),\n",
    "    'Ore_Pulp_Flow': (train_and_test_ds['Ore_Pulp_Flow'].min(), train_and_test_ds['Ore_Pulp_Flow'].max()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef3308f8-0d6c-4a17-9dfa-2cccaa9b00ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_custom_timestamp(date):\n",
    "    # IDENTIFY PREVIOUS ROW\n",
    "    row_id = oot_ds.loc[oot_ds['date'] == date].index.tolist()[0]\n",
    "\n",
    "    # GET ROW VALUES\n",
    "    oot_ds_row = pd.DataFrame(oot_ds.loc[row_id].values.reshape(1, -1), columns=oot_ds.columns)\n",
    "    \n",
    "    si_baseline = si_model.predict(oot_ds_row[si_input_columns])[0]\n",
    "    fe_baseline = fe_model.predict(oot_ds_row[fe_input_columns])[0]\n",
    "    penalty_value = -1e6  # large negative number to penalize constraint violation\n",
    "\n",
    "    # Define the objective function \n",
    "    def constrained_objective(Starch_Flow, Amina_Flow, Ore_Pulp_Flow):\n",
    "        input_vector = oot_ds_row.copy()\n",
    "        input_vector[\"Starch_Flow\"] = Starch_Flow\n",
    "        input_vector[\"Amina_Flow\"] = Amina_Flow\n",
    "        input_vector[\"Ore_Pulp_Flow\"] = Ore_Pulp_Flow\n",
    "\n",
    "        y1 = fe_model.predict(input_vector[fe_input_columns])[0]  # objective\n",
    "        y2 = si_model.predict(input_vector[si_input_columns])[0]  # constraint\n",
    "        \n",
    "        if y2 > si_baseline:\n",
    "            return penalty_value  # penalize invalid solutions\n",
    "        return y1\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=constrained_objective,\n",
    "        pbounds=pbounds,\n",
    "        random_state=42,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    optimizer.maximize(\n",
    "        init_points=5,\n",
    "        n_iter=30,\n",
    "    )\n",
    "\n",
    "    # Best result\n",
    "    print(\"Current parameters and best parameters found:\")\n",
    "    starch_flow_current = oot_ds_row['Starch_Flow'].values[0]\n",
    "    amina_flow_current = oot_ds_row['Amina_Flow'].values[0]\n",
    "    ore_pulp_flow_current = oot_ds_row['Ore_Pulp_Flow'].values[0]\n",
    "\n",
    "    starch_flow_optimised = optimizer.max['params']['Starch_Flow']\n",
    "    amina_flow_optimised = optimizer.max['params']['Amina_Flow']\n",
    "    ore_pulp_flow_optimised = optimizer.max['params']['Ore_Pulp_Flow']\n",
    "    \n",
    "    print(f\"Starch Flow Sepoint (current, optimised): {starch_flow_current:.4f}, {starch_flow_optimised:.4f}\")\n",
    "    print(f\"Amina Flow Sepoint (current, optimised): {amina_flow_current:.4f}, {amina_flow_optimised:.4f}\")\n",
    "    print(f\"Ore Pulp Flow Sepoint (current, optimised): {ore_pulp_flow_current:.4f}, {ore_pulp_flow_optimised:.4f}\")\n",
    "    \n",
    "    input_vector = oot_ds_row.copy()\n",
    "    input_vector[\"Starch_Flow\"] = optimizer.max['params']['Starch_Flow']\n",
    "    input_vector[\"Amina_Flow\"] = optimizer.max['params']['Amina_Flow']\n",
    "    input_vector[\"Ore_Pulp_Flow\"] = optimizer.max['params']['Ore_Pulp_Flow']\n",
    "    si_optimised = si_model.predict(input_vector[si_input_columns])[0]\n",
    "    fe_optimised = fe_model.predict(input_vector[fe_input_columns])[0]\n",
    "    \n",
    "    print(f\"Maximum Model Si prediction (current, optimised): {si_baseline:.4f}, {si_optimised:.4f}\")\n",
    "    print(f\"Maximum Model Fe prediction (current, optimised): {fe_baseline:.4f}, {fe_optimised:.4f}\")\n",
    "\n",
    "    return([date, \n",
    "            starch_flow_current, \n",
    "            starch_flow_optimised, \n",
    "            amina_flow_current, \n",
    "            amina_flow_optimised, \n",
    "            ore_pulp_flow_current,\n",
    "            ore_pulp_flow_optimised,\n",
    "            si_baseline,\n",
    "            si_optimised,\n",
    "            fe_baseline,\n",
    "            fe_optimised,\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e78dd8-bb0a-4cef-a2de-b8b919a550c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5.2 Run Optimisation for a Selected Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24a46545-e3be-4ff2-b27b-1010d43b9c62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MANUAL INPUTS \n",
    "date = '2017-08-25 01:00:00'\n",
    "run_custom_timestamp(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90787103-c05c-4af6-9f10-e7717052b9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5.3 Run Counterfactual for all OOT hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4f6143-dd85-4397-9a66-e3aa323de4a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"Y29sdW1uX25hbWVzID0gWwogICAgImRhdGUiLCAKICAgICJTdGFyY2hfRmxvdyIsIAogICAgIlN0YXJjaF9GbG93X29wdGltaXNlZCIsIAogICAgIkFtaW5hX0Zsb3ciLCAKICAgICJBbWluYV9GbG93X29wdGltaXNlZCIsIAogICAgIk9yZV9QdWxwX0Zsb3ciLAogICAgIk9yZV9QdWxwX0Zsb3dfb3B0aW1pc2VkIiwKICAgICJTaV9iYXNlbGluZSIsCiAgICAiU2lfb3B0aW1pc2VkIiwKICAgICJGZV9iYXNlbGluZSIsCiAgICAiRmVfb3B0aW1pc2VkIgpdCgpmb3IgaWR4LCBkYXRlIGluIGVudW1lcmF0ZShvb3RfZHNbJ2RhdGUnXVswOjEwMF0pOgogICAgcHJpbnQoZGF0ZSkKICAgIHJlc3VsdHMgPSBydW5fY3VzdG9tX3RpbWVzdGFtcChkYXRlKQogICAgaWYgaWR4ID09IDA6CiAgICAgICAgcmVzdWx0c19kZiA9IHBkLkRhdGFGcmFtZShbcmVzdWx0c10sIGNvbHVtbnM9Y29sdW1uX25hbWVzKQogICAgZWxzZToKICAgICAgICByZXN1bHRzX2RmID0gcGQuY29uY2F0KFtyZXN1bHRzX2RmLCBwZC5EYXRhRnJhbWUoW3Jlc3VsdHNdLCBjb2x1bW5zPWNvbHVtbl9uYW1lcyldLCBpZ25vcmVfaW5kZXg9VHJ1ZSkKCnJlc3VsdHNfZGZbJ1NpX0NoYW5nZSddID0gcmVzdWx0c19kZlsnU2lfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydTaV9iYXNlbGluZSddCnJlc3VsdHNfZGZbJ0ZlX1VwbGlmdCddID0gcmVzdWx0c19kZlsnRmVfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydGZV9iYXNlbGluZSddCmRpc3BsYXkocmVzdWx0c19kZik=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView3395c8e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView3395c8e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView3395c8e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView3395c8e) SELECT `date`,SUM(`Fe_baseline`) `column_d7f5e8ed1263`,SUM(`Fe_optimised`) `column_d7f5e8ed1266` FROM q GROUP BY `date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView3395c8e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Fe Concentrate",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": false,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "date",
             "id": "column_d7f5e8ed1260"
            },
            "y": [
             {
              "column": "Fe_baseline",
              "id": "column_d7f5e8ed1263",
              "transform": "SUM"
             },
             {
              "column": "Fe_optimised",
              "id": "column_d7f5e8ed1266",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_d7f5e8ed1263": {
             "name": "Fe Concentrate % (current setpoints)",
             "type": "line",
             "yAxis": 0
            },
            "column_d7f5e8ed1266": {
             "name": "Fe Concentrate % (optimised setpoints)",
             "type": "line",
             "yAxis": 1
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Datetime"
            },
            "type": "-"
           },
           "yAxis": [
            {
             "rangeMax": 70,
             "rangeMin": 60,
             "type": "-"
            },
            {
             "opposite": true,
             "rangeMax": 70,
             "rangeMin": 60,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "df433bd0-1439-4b54-9f0d-1cc0129e334b",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "date",
           "type": "column"
          },
          {
           "alias": "column_d7f5e8ed1263",
           "args": [
            {
             "column": "Fe_baseline",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_d7f5e8ed1266",
           "args": [
            {
             "column": "Fe_optimised",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"Y29sdW1uX25hbWVzID0gWwogICAgImRhdGUiLCAKICAgICJTdGFyY2hfRmxvdyIsIAogICAgIlN0YXJjaF9GbG93X29wdGltaXNlZCIsIAogICAgIkFtaW5hX0Zsb3ciLCAKICAgICJBbWluYV9GbG93X29wdGltaXNlZCIsIAogICAgIk9yZV9QdWxwX0Zsb3ciLAogICAgIk9yZV9QdWxwX0Zsb3dfb3B0aW1pc2VkIiwKICAgICJTaV9iYXNlbGluZSIsCiAgICAiU2lfb3B0aW1pc2VkIiwKICAgICJGZV9iYXNlbGluZSIsCiAgICAiRmVfb3B0aW1pc2VkIgpdCgpmb3IgaWR4LCBkYXRlIGluIGVudW1lcmF0ZShvb3RfZHNbJ2RhdGUnXVswOjEwMF0pOgogICAgcHJpbnQoZGF0ZSkKICAgIHJlc3VsdHMgPSBydW5fY3VzdG9tX3RpbWVzdGFtcChkYXRlKQogICAgaWYgaWR4ID09IDA6CiAgICAgICAgcmVzdWx0c19kZiA9IHBkLkRhdGFGcmFtZShbcmVzdWx0c10sIGNvbHVtbnM9Y29sdW1uX25hbWVzKQogICAgZWxzZToKICAgICAgICByZXN1bHRzX2RmID0gcGQuY29uY2F0KFtyZXN1bHRzX2RmLCBwZC5EYXRhRnJhbWUoW3Jlc3VsdHNdLCBjb2x1bW5zPWNvbHVtbl9uYW1lcyldLCBpZ25vcmVfaW5kZXg9VHJ1ZSkKCnJlc3VsdHNfZGZbJ1NpX0NoYW5nZSddID0gcmVzdWx0c19kZlsnU2lfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydTaV9iYXNlbGluZSddCnJlc3VsdHNfZGZbJ0ZlX1VwbGlmdCddID0gcmVzdWx0c19kZlsnRmVfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydGZV9iYXNlbGluZSddCmRpc3BsYXkocmVzdWx0c19kZik=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView26fe04e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView26fe04e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView26fe04e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView26fe04e) SELECT `date`,SUM(`Si_baseline`) `column_d7f5e8ed1274`,SUM(`Si_optimised`) `column_d7f5e8ed1277` FROM q GROUP BY `date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView26fe04e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Si Concentrate",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "date",
             "id": "column_d7f5e8ed1271"
            },
            "y": [
             {
              "column": "Si_baseline",
              "id": "column_d7f5e8ed1274",
              "transform": "SUM"
             },
             {
              "column": "Si_optimised",
              "id": "column_d7f5e8ed1277",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_d7f5e8ed1274": {
             "name": "Si Concentrate % (current setpoints)",
             "type": "line",
             "yAxis": 0
            },
            "column_d7f5e8ed1277": {
             "name": "Si Concentrate % (optimised setpoints)",
             "type": "line",
             "yAxis": 1
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Datetime"
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "8d38c3d3-d2bf-4361-a36a-0f9935d54660",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "date",
           "type": "column"
          },
          {
           "alias": "column_d7f5e8ed1274",
           "args": [
            {
             "column": "Si_baseline",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          },
          {
           "alias": "column_d7f5e8ed1277",
           "args": [
            {
             "column": "Si_optimised",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"Y29sdW1uX25hbWVzID0gWwogICAgImRhdGUiLCAKICAgICJTdGFyY2hfRmxvdyIsIAogICAgIlN0YXJjaF9GbG93X29wdGltaXNlZCIsIAogICAgIkFtaW5hX0Zsb3ciLCAKICAgICJBbWluYV9GbG93X29wdGltaXNlZCIsIAogICAgIk9yZV9QdWxwX0Zsb3ciLAogICAgIk9yZV9QdWxwX0Zsb3dfb3B0aW1pc2VkIiwKICAgICJTaV9iYXNlbGluZSIsCiAgICAiU2lfb3B0aW1pc2VkIiwKICAgICJGZV9iYXNlbGluZSIsCiAgICAiRmVfb3B0aW1pc2VkIgpdCgpmb3IgaWR4LCBkYXRlIGluIGVudW1lcmF0ZShvb3RfZHNbJ2RhdGUnXVswOjEwMF0pOgogICAgcHJpbnQoZGF0ZSkKICAgIHJlc3VsdHMgPSBydW5fY3VzdG9tX3RpbWVzdGFtcChkYXRlKQogICAgaWYgaWR4ID09IDA6CiAgICAgICAgcmVzdWx0c19kZiA9IHBkLkRhdGFGcmFtZShbcmVzdWx0c10sIGNvbHVtbnM9Y29sdW1uX25hbWVzKQogICAgZWxzZToKICAgICAgICByZXN1bHRzX2RmID0gcGQuY29uY2F0KFtyZXN1bHRzX2RmLCBwZC5EYXRhRnJhbWUoW3Jlc3VsdHNdLCBjb2x1bW5zPWNvbHVtbl9uYW1lcyldLCBpZ25vcmVfaW5kZXg9VHJ1ZSkKCnJlc3VsdHNfZGZbJ1NpX0NoYW5nZSddID0gcmVzdWx0c19kZlsnU2lfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydTaV9iYXNlbGluZSddCnJlc3VsdHNfZGZbJ0ZlX1VwbGlmdCddID0gcmVzdWx0c19kZlsnRmVfb3B0aW1pc2VkJ10gLSByZXN1bHRzX2RmWydGZV9iYXNlbGluZSddCmRpc3BsYXkocmVzdWx0c19kZik=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewcf97e6b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewcf97e6b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewcf97e6b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewcf97e6b) ,min_max AS (SELECT `Fe_Uplift`,(SELECT MAX(`Fe_Uplift`) FROM q) `target_column_max`,(SELECT MIN(`Fe_Uplift`) FROM q) `target_column_min` FROM q) ,histogram_meta AS (SELECT `Fe_Uplift`,`target_column_min` `min_value`,IF(`target_column_max` = `target_column_min`,`target_column_max` + 1,`target_column_max`) `max_value`,(`target_column_max` - `target_column_min`) / 30 `step` FROM min_max) SELECT IF(ISNULL(`Fe_Uplift`),NULL,LEAST(WIDTH_BUCKET(`Fe_Uplift`,`min_value`,`max_value`,30),30)) `Fe_Uplift_BIN`,FIRST(`min_value` + ((IF(ISNULL(`Fe_Uplift`),NULL,LEAST(WIDTH_BUCKET(`Fe_Uplift`,`min_value`,`max_value`,30),30)) - 1) * `step`)) `Fe_Uplift_BIN_LOWER_BOUND`,FIRST(`step`) `Fe_Uplift_BIN_STEP`,COUNT(`Fe_Uplift`) `COUNT` FROM histogram_meta GROUP BY `Fe_Uplift_BIN`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewcf97e6b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Fe Uplift",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "Fe_Uplift",
             "id": "column_d7f5e8ed1279"
            }
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "histogram",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numBins": 30,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "title": {
             "text": "Fe % Optimised-Baseline"
            },
            "type": "linear"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "34ada1c0-740e-4811-87f1-3d6f371d17e6",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.75,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "Fe_Uplift_BIN",
           "type": "column"
          }
         ],
         "selects": [
          {
           "alias": "Fe_Uplift_BIN",
           "args": [
            {
             "column": "Fe_Uplift",
             "type": "column"
            },
            {
             "number": 30,
             "type": "number"
            }
           ],
           "function": "BIN",
           "type": "function"
          },
          {
           "alias": "Fe_Uplift_BIN_LOWER_BOUND",
           "args": [
            {
             "column": "Fe_Uplift",
             "type": "column"
            },
            {
             "number": 30,
             "type": "number"
            }
           ],
           "function": "BIN_LOWER_BOUND",
           "type": "function"
          },
          {
           "alias": "Fe_Uplift_BIN_STEP",
           "args": [
            {
             "column": "Fe_Uplift",
             "type": "column"
            },
            {
             "number": 30,
             "type": "number"
            }
           ],
           "function": "BIN_STEP",
           "type": "function"
          },
          {
           "alias": "COUNT",
           "args": [
            {
             "column": "Fe_Uplift",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_names = [\n",
    "    \"date\", \n",
    "    \"Starch_Flow\", \n",
    "    \"Starch_Flow_optimised\", \n",
    "    \"Amina_Flow\", \n",
    "    \"Amina_Flow_optimised\", \n",
    "    \"Ore_Pulp_Flow\",\n",
    "    \"Ore_Pulp_Flow_optimised\",\n",
    "    \"Si_baseline\",\n",
    "    \"Si_optimised\",\n",
    "    \"Fe_baseline\",\n",
    "    \"Fe_optimised\"\n",
    "]\n",
    "\n",
    "for idx, date in enumerate(oot_ds['date'][0:100]):\n",
    "    print(date)\n",
    "    results = run_custom_timestamp(date)\n",
    "    if idx == 0:\n",
    "        results_df = pd.DataFrame([results], columns=column_names)\n",
    "    else:\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([results], columns=column_names)], ignore_index=True)\n",
    "\n",
    "results_df['Si_Change'] = results_df['Si_optimised'] - results_df['Si_baseline']\n",
    "results_df['Fe_Uplift'] = results_df['Fe_optimised'] - results_df['Fe_baseline']\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9ee2ae-abaf-4d17-9f5a-9838f09b036b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the table\n",
    "table_name = \"gold_iron_ore_optimisations\"\n",
    "spark_results_df = spark.createDataFrame(results_df)\n",
    "spark_results_df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(f\"{DEFAULT_CATALOG}.{DEFAULT_SCHEMA}.{table_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "05. Optimisation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
